![](https://media.giphy.com/media/dCBZtA2iuNqZW/giphy-downsized.gif)
![](https://media.giphy.com/media/dCBZtA2iuNqZW/giphy-downsized.gif)
![](https://media.giphy.com/media/dCBZtA2iuNqZW/giphy-downsized.gif)


# MIRROR SOURCE

> http://sandlab.cs.uchicago.edu/fawkes/#paper

# WTF is this ?

This repo is a mirror backup of [Fawkes: Protecting Privacy against Unauthorized Deep Learning Models](http://sandlab.cs.uchicago.edu/fawkes/#paper)

A tool that introduces pixel level changes within an image confounding image recognition algorithms that use Deep Learning Models.

The tool is described as follows in this  [PAPER](http://people.cs.uchicago.edu/~ravenben/publications/abstracts/fawkes-usenix20.html)

> A system that helps individuals inoculate their images against unauthorized facial recognition models. Fawkes achieves this by helping users add imperceptible pixel-level changes (we call
> them "cloaks") to their own photos before releasing them. When used to train facial recognition models, these "cloaked" images produce functional models that consistently cause normal images
> of the user to be misidentified. We experimentally demonstrate that Fawkes provides 95+% protection against user recognition regardless of how trackers train their models. Even when clean,
> uncloaked images are "leaked" to the tracker and used for training, Fawkes can still maintain an 80+% protection success rate. We achieve 100% success in experiments against today's
> state-of-the-art facial recognition services. Finally, we show that Fawkes is robust against a variety of countermeasures that try to detect or disrupt image cloaks.
 

## TLDR LOL Version
This tool fcuks up your profile pictures that you put up on social media, making it hard for facial recognition companies to use your images for training their facial recognition
algorithms by sneakily getting your express permission to do so by forcing you to agree to their T&C's when you sign up for their service. LOL 

# Why was this repo made ?

Since a lot of work and investment in the Artifical Intelligence space is going into advancing orwellian technologies such as __Facial Recognition__ , A tool such as this will eventually draw the
wrath of vested interests, meaning it may be taken down without notice.

# Installation

For installation please select your OS :

N | OS | URL
--- | --- | ---
1 | Win10 | [CLICK ME](https://github.com/sztekz/FawkesImageCloak/tree/main/Win10)
2 | MacOS | [CLICK ME](https://github.com/sztekz/FawkesImageCloak/tree/main/MacOS)
3 | NIX   | [CLICK ME](https://github.com/sztekz/FawkesImageCloak/tree/main/nix)


## Usage 

1. For both Win10 and MacOS there is a simple file upload and encode function.


# License

> This repo is a mirror, T&C's of the source are applicable to the files here. Only this file which you are reading has been made by the repo owner.

# CryptoCoffee

> Well who doesn't like coffee ? :D

[![](d.png)](https://sites.google.com/view/cryptocoffee/)
